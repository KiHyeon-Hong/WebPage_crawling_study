xpath : element의 경로 //*[@id="asdasd.."]
크롬에서는 xpath를 쉽게 얻을 수 있음

정규식 : 규칙을 가진 문자열을 표현하는 식

user-agent : 어떤 페이지를 보여줄까? 근데 진짜 사람 맞아?(접속을 맏을 수도 있으므로 변경해줘야 할 수도 있음)

requests : 빠르다, 동적 웹 페이지에서는 사용이 불가능
selenium : 느리다, 동적 웹 페이지에서 사용이 가능하다
가져온 데이터를 bs4를 이용해서 가공을 한다

selenium 경우 로그인 등이 가능하다. 주의할 점은 크롬 버전에 맞는 드라이버를 깔아야 한다

find_element(s)_by_id : id로 찾기
find_element(s)_by_class_name : class name으로 찾기
find_element(s)_by_link_text : 링크 text로 찾기
find_element(s)_by_xpath : xpath로 찾기

click() : 클릭
send_keys() : 글자 입력

selenium -> 로딩 같은 경우는 기다릴 필요가 있다
elem = WebDriverWait(browser) ...

스크롤 내리기도 가능합니다

BeautifulSoup의 메소드
find : 조건에 맞는 첫번째 element
find_all : 조건에 맞는 모든 element 리스트
find_next_sibling(s) : 다음 형제 찾기
find_previous_sibling(s) : 이전 형제 찾기

soup["href"] : 속성
soup.get_text() : 텍스트


이미지 다운로드 가능
csv 형태로 저장도 가능 -> 인코등 주의 (utf-8-sig)

headless 크롬 -> 브라우저를 띄우지 않고 동작, 때로는 에이전트 정의 필요, 59버전 부터 가능

